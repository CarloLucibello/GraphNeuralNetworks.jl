<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · GraphNeuralNetworks.jl</title><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>GraphNeuralNetworks.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li><li><a class="tocitem" href="dev/">Developer Notes</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="GraphNeuralNetworks"><a class="docs-heading-anchor" href="#GraphNeuralNetworks">GraphNeuralNetworks</a><a id="GraphNeuralNetworks-1"></a><a class="docs-heading-anchor-permalink" href="#GraphNeuralNetworks" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl">GraphNeuralNetworks</a>.</p><ul><li><a href="#GraphNeuralNetworks.ChebConv"><code>GraphNeuralNetworks.ChebConv</code></a></li><li><a href="#GraphNeuralNetworks.EdgeConv"><code>GraphNeuralNetworks.EdgeConv</code></a></li><li><a href="#GraphNeuralNetworks.FeaturedGraph"><code>GraphNeuralNetworks.FeaturedGraph</code></a></li><li><a href="#GraphNeuralNetworks.GATConv"><code>GraphNeuralNetworks.GATConv</code></a></li><li><a href="#GraphNeuralNetworks.GCNConv"><code>GraphNeuralNetworks.GCNConv</code></a></li><li><a href="#GraphNeuralNetworks.GINConv"><code>GraphNeuralNetworks.GINConv</code></a></li><li><a href="#GraphNeuralNetworks.GatedGraphConv"><code>GraphNeuralNetworks.GatedGraphConv</code></a></li><li><a href="#GraphNeuralNetworks.GlobalPool"><code>GraphNeuralNetworks.GlobalPool</code></a></li><li><a href="#GraphNeuralNetworks.GraphConv"><code>GraphNeuralNetworks.GraphConv</code></a></li><li><a href="#GraphNeuralNetworks.LocalPool"><code>GraphNeuralNetworks.LocalPool</code></a></li><li><a href="#GraphNeuralNetworks.MessagePassing"><code>GraphNeuralNetworks.MessagePassing</code></a></li><li><a href="#GraphNeuralNetworks.TopKPool"><code>GraphNeuralNetworks.TopKPool</code></a></li><li><a href="#GraphNeuralNetworks.add_self_loops-Tuple{FeaturedGraph{var&quot;#s10&quot;} where var&quot;#s10&quot;&lt;:(Tuple{T, T, V} where {T&lt;:(AbstractVector{T} where T), V})}"><code>GraphNeuralNetworks.add_self_loops</code></a></li><li><a href="#GraphNeuralNetworks.bypass_graph"><code>GraphNeuralNetworks.bypass_graph</code></a></li><li><a href="#GraphNeuralNetworks.edge_feature-Tuple{FeaturedGraph}"><code>GraphNeuralNetworks.edge_feature</code></a></li><li><a href="#GraphNeuralNetworks.edge_index-Tuple{FeaturedGraph{var&quot;#s11&quot;} where var&quot;#s11&quot;&lt;:(Tuple{T, T, V} where {T&lt;:(AbstractVector{T} where T), V})}"><code>GraphNeuralNetworks.edge_index</code></a></li><li><a href="#GraphNeuralNetworks.global_feature-Tuple{FeaturedGraph}"><code>GraphNeuralNetworks.global_feature</code></a></li><li><a href="#GraphNeuralNetworks.graph-Tuple{FeaturedGraph}"><code>GraphNeuralNetworks.graph</code></a></li><li><a href="#GraphNeuralNetworks.message"><code>GraphNeuralNetworks.message</code></a></li><li><a href="#GraphNeuralNetworks.node_feature-Tuple{FeaturedGraph}"><code>GraphNeuralNetworks.node_feature</code></a></li><li><a href="#GraphNeuralNetworks.normalized_laplacian"><code>GraphNeuralNetworks.normalized_laplacian</code></a></li><li><a href="#GraphNeuralNetworks.propagate"><code>GraphNeuralNetworks.propagate</code></a></li><li><a href="#GraphNeuralNetworks.scaled_laplacian"><code>GraphNeuralNetworks.scaled_laplacian</code></a></li><li><a href="#GraphNeuralNetworks.update"><code>GraphNeuralNetworks.update</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.ChebConv" href="#GraphNeuralNetworks.ChebConv"><code>GraphNeuralNetworks.ChebConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ChebConv(in=&gt;out, k; bias=true, init=glorot_uniform)</code></pre><p>Chebyshev spectral graph convolutional layer.</p><p><strong>Arguments</strong></p><ul><li><code>in</code>: The dimension of input features.</li><li><code>out</code>: The dimension of output features.</li><li><code>k</code>: The order of Chebyshev polynomial.</li><li><code>bias</code>: Add learnable bias.</li><li><code>init</code>: Weights&#39; initializer.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/conv.jl#L64-L76">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.EdgeConv" href="#GraphNeuralNetworks.EdgeConv"><code>GraphNeuralNetworks.EdgeConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">EdgeConv(nn; aggr=max)</code></pre><p>Edge convolutional layer.</p><p><strong>Arguments</strong></p><ul><li><code>nn</code>: A neural network (e.g. a Dense layer or a MLP). </li><li><code>aggr</code>: An aggregate function applied to the result of message function. <code>+</code>, <code>max</code> and <code>mean</code> are available.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/conv.jl#L317-L326">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.FeaturedGraph" href="#GraphNeuralNetworks.FeaturedGraph"><code>GraphNeuralNetworks.FeaturedGraph</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FeaturedGraph(g; [graph_type, dir, num_nodes, nf, ef, gf])
FeaturedGraph(fg::FeaturedGraph; [nf, ef, gf])</code></pre><p>A type representing a graph structure and storing also arrays  that contain features associated to nodes, edges, and the whole graph. </p><p>A <code>FeaturedGraph</code> can be constructed out of different objects <code>g</code> representing the connections inside the graph, while the internal representation type is governed by <code>graph_type</code>.  When constructed from another featured graph <code>fg</code>, the internal graph representation is preserved and shared. </p><p>A <code>FeaturedGraph</code> is a LightGraphs&#39; <code>AbstractGraph</code>, therefore any functionality from the LightGraphs&#39; graph library can be used on it.</p><p><strong>Arguments</strong></p><ul><li><code>g</code>: Some data representing the graph topology. Possible type are <ul><li>An adjacency matrix</li><li>An adjacency list.</li><li>A tuple containing the source and target vectors (COO representation)</li><li>A LightGraphs&#39; graph.</li></ul></li><li><code>graph_type</code>: A keyword argument that specifies                the underlying representation used by the FeaturedGraph.                Currently supported values are <ul><li><code>:coo</code>. Graph represented as a tuple <code>(source, target)</code>, such that the <code>k</code>-th edge          connects the node <code>source[k]</code> to node <code>target[k]</code>.         Optionally, also edge weights can be given: <code>(source, target, weights)</code>.</li><li><code>:sparse</code>. A sparse adjacency matrix representation.</li><li><code>:dense</code>. A dense adjacency matrix representation.  </li></ul>Default <code>:coo</code>.</li><li><code>dir</code>. The assumed edge direction when given adjacency matrix or adjacency list input data <code>g</code>.        Possible values are <code>:out</code> and <code>:in</code>. Defaul <code>:out</code>.</li><li><code>num_nodes</code>. The number of nodes. If not specified, inferred from <code>g</code>. Default nothing.</li><li><code>nf</code>: Node features. Either nothing, or an array whose last dimension has size num_nodes. Default nothing.</li><li><code>ef</code>: Edge features. Either nothing, or an array whose last dimension has size num_edges. Default nothing.</li><li><code>gf</code>: Global features. Default nothing. </li></ul><p><strong>Usage.</strong></p><pre><code class="nohighlight hljs">using Flux, GraphNeuralNetworks

# Construct from adjacency list representation
g = [[2,3], [1,4,5], [1], [2,5], [2,4]]
fg = FeaturedGraph(g)

# Number of nodes and edges
fg.num_nodes  # 5
fg.num_edges  # 10 

# Same graph in COO representation
s = [1,1,2,2,2,3,4,4,5,5]
t = [2,3,1,4,5,3,2,5,2,4]
fg = FeaturedGraph((s, t))
fg = FeaturedGraph(s, t) # other convenience constructor

# From a LightGraphs&#39; graph
fg = FeaturedGraph(erdos_renyi(100, 20))

# Copy featured graph while also adding node features
fg = FeaturedGraph(fg, nf=rand(100, 5))

# Send to gpu
fg = fg |&gt; gpu

# Collect edges&#39; source and target nodes.
# Both source and target are vectors of length num_edges
source, target = edge_index(fg)</code></pre><p>See also <a href="#GraphNeuralNetworks.graph-Tuple{FeaturedGraph}"><code>graph</code></a>, <a href="#GraphNeuralNetworks.edge_index-Tuple{FeaturedGraph{var&quot;#s11&quot;} where var&quot;#s11&quot;&lt;:(Tuple{T, T, V} where {T&lt;:(AbstractVector{T} where T), V})}"><code>edge_index</code></a>, <a href="#GraphNeuralNetworks.node_feature-Tuple{FeaturedGraph}"><code>node_feature</code></a>, <a href="#GraphNeuralNetworks.edge_feature-Tuple{FeaturedGraph}"><code>edge_feature</code></a>, and <a href="#GraphNeuralNetworks.global_feature-Tuple{FeaturedGraph}"><code>global_feature</code></a> </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/featuredgraph.jl#L13-L86">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.GATConv" href="#GraphNeuralNetworks.GATConv"><code>GraphNeuralNetworks.GATConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GATConv(in =&gt; out;
        heads=1,
        concat=true,
        init=glorot_uniform    
        bias=true, 
        negative_slope=0.2)</code></pre><p>Graph attentional layer.</p><p><strong>Arguments</strong></p><ul><li><code>in</code>: The dimension of input features.</li><li><code>out</code>: The dimension of output features.</li><li><code>bias::Bool</code>: Keyword argument, whether to learn the additive bias.</li><li><code>heads</code>: Number attention heads </li><li><code>concat</code>: Concatenate layer output or not. If not, layer output is averaged over the heads.</li><li><code>negative_slope::Real</code>: Keyword argument, the parameter of LeakyReLU.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/conv.jl#L175-L193">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.GCNConv" href="#GraphNeuralNetworks.GCNConv"><code>GraphNeuralNetworks.GCNConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GCNConv(in =&gt; out, σ=identity; bias=true, init=glorot_uniform)</code></pre><p>Graph convolutional layer.</p><p><strong>Arguments</strong></p><ul><li><code>in</code>: The dimension of input features.</li><li><code>out</code>: The dimension of output features.</li><li><code>σ</code>: Activation function.</li><li><code>bias</code>: Add learnable bias.</li><li><code>init</code>: Weights&#39; initializer.</li></ul><p>The input to the layer is a node feature array <code>X</code>  of size <code>(num_features, num_nodes)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/conv.jl#L1-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.GINConv" href="#GraphNeuralNetworks.GINConv"><code>GraphNeuralNetworks.GINConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GINConv(nn; eps = 0f0)</code></pre><p>Graph Isomorphism Network.</p><p><strong>Arguments</strong></p><ul><li><code>nn</code>: A neural network/layer.</li><li><code>eps</code>: Weighting factor.</li></ul><p>The definition of this is as defined in the original paper, Xu et. al. (2018) https://arxiv.org/abs/1810.00826.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/conv.jl#L355-L367">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.GatedGraphConv" href="#GraphNeuralNetworks.GatedGraphConv"><code>GraphNeuralNetworks.GatedGraphConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GatedGraphConv(out, num_layers; aggr=+, init=glorot_uniform)</code></pre><p>Gated graph convolution layer.</p><p><strong>Arguments</strong></p><ul><li><code>out</code>: The dimension of output features.</li><li><code>num_layers</code>: The number of gated recurrent unit.</li><li><code>aggr</code>: An aggregate function applied to the result of message function. <code>+</code>, <code>-</code>,</li></ul><p><code>*</code>, <code>/</code>, <code>max</code>, <code>min</code> and <code>mean</code> are available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/conv.jl#L258-L269">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.GlobalPool" href="#GraphNeuralNetworks.GlobalPool"><code>GraphNeuralNetworks.GlobalPool</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GlobalPool(aggr, dim...)</code></pre><p>Global pooling layer.</p><p>It pools all features with <code>aggr</code> operation.</p><p><strong>Arguments</strong></p><ul><li><code>aggr</code>: An aggregate function applied to pool all features.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/pool.jl#L3-L13">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.GraphConv" href="#GraphNeuralNetworks.GraphConv"><code>GraphNeuralNetworks.GraphConv</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GraphConv(in =&gt; out, σ=identity, aggr=+; bias=true, init=glorot_uniform)</code></pre><p>Graph neural network layer.</p><p><strong>Arguments</strong></p><ul><li><code>in</code>: The dimension of input features.</li><li><code>out</code>: The dimension of output features.</li><li><code>σ</code>: Activation function.</li><li><code>aggr</code>: An aggregate function applied to the result of message function. <code>+</code>, <code>-</code>,</li></ul><p><code>*</code>, <code>/</code>, <code>max</code>, <code>min</code> and <code>mean</code> are available.</p><ul><li><code>bias</code>: Add learnable bias.</li><li><code>init</code>: Weights&#39; initializer.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/conv.jl#L120-L134">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.LocalPool" href="#GraphNeuralNetworks.LocalPool"><code>GraphNeuralNetworks.LocalPool</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">LocalPool(aggr, cluster)</code></pre><p>Local pooling layer.</p><p>It pools features with <code>aggr</code> operation accroding to <code>cluster</code>. It is implemented with <code>scatter</code> operation.</p><p><strong>Arguments</strong></p><ul><li><code>aggr</code>: An aggregate function applied to pool all features.</li><li><code>cluster</code>: An index structure which indicates what features to aggregate with.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/pool.jl#L25-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.MessagePassing" href="#GraphNeuralNetworks.MessagePassing"><code>GraphNeuralNetworks.MessagePassing</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MessagePassing</code></pre><p>The abstract type from which all message passing layers are derived.</p><p>Related methods are <a href="#GraphNeuralNetworks.propagate"><code>propagate</code></a>, <a href="#GraphNeuralNetworks.message"><code>message</code></a>, <a href="#GraphNeuralNetworks.update"><code>update</code></a>, <a href="@ref"><code>update_edge</code></a>, and <a href="@ref"><code>update_global</code></a>. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/msgpass.jl#L3-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.TopKPool" href="#GraphNeuralNetworks.TopKPool"><code>GraphNeuralNetworks.TopKPool</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TopKPool(adj, k, in_channel)</code></pre><p>Top-k pooling layer.</p><p><strong>Arguments</strong></p><ul><li><code>adj</code>: Adjacency matrix  of a graph.</li><li><code>k</code>: Top-k nodes are selected to pool together.</li><li><code>in_channel</code>: The dimension of input channel.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/pool.jl#L44-L54">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.add_self_loops-Tuple{FeaturedGraph{var&quot;#s10&quot;} where var&quot;#s10&quot;&lt;:(Tuple{T, T, V} where {T&lt;:(AbstractVector{T} where T), V})}" href="#GraphNeuralNetworks.add_self_loops-Tuple{FeaturedGraph{var&quot;#s10&quot;} where var&quot;#s10&quot;&lt;:(Tuple{T, T, V} where {T&lt;:(AbstractVector{T} where T), V})}"><code>GraphNeuralNetworks.add_self_loops</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">add_self_loops(fg::FeaturedGraph)</code></pre><p>Return a featured graph with the same features as <code>fg</code> but also adding edges connecting the nodes to themselves.</p><p>Nodes with already existing self-loops will obtain a second self-loop.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/featuredgraph.jl#L355-L363">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.bypass_graph" href="#GraphNeuralNetworks.bypass_graph"><code>GraphNeuralNetworks.bypass_graph</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">bypass_graph(nf_func, ef_func, gf_func)</code></pre><p>Bypassing graph in FeaturedGraph and let other layer process (node, edge and global)features only.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/misc.jl#L1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.edge_feature-Tuple{FeaturedGraph}" href="#GraphNeuralNetworks.edge_feature-Tuple{FeaturedGraph}"><code>GraphNeuralNetworks.edge_feature</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">edge_feature(fg::FeaturedGraph)</code></pre><p>Return the edge features of <code>fg</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/featuredgraph.jl#L268-L272">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.edge_index-Tuple{FeaturedGraph{var&quot;#s11&quot;} where var&quot;#s11&quot;&lt;:(Tuple{T, T, V} where {T&lt;:(AbstractVector{T} where T), V})}" href="#GraphNeuralNetworks.edge_index-Tuple{FeaturedGraph{var&quot;#s11&quot;} where var&quot;#s11&quot;&lt;:(Tuple{T, T, V} where {T&lt;:(AbstractVector{T} where T), V})}"><code>GraphNeuralNetworks.edge_index</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">edge_index(fg::FeaturedGraph)</code></pre><p>Return a tuple containing two vectors, respectively storing  the source and target nodes for each edges in <code>fg</code>.</p><pre><code class="language-julia hljs">s, t = edge_index(fg)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/featuredgraph.jl#L155-L164">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.global_feature-Tuple{FeaturedGraph}" href="#GraphNeuralNetworks.global_feature-Tuple{FeaturedGraph}"><code>GraphNeuralNetworks.global_feature</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">global_feature(fg::FeaturedGraph)</code></pre><p>Return the global features of <code>fg</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/featuredgraph.jl#L275-L279">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.graph-Tuple{FeaturedGraph}" href="#GraphNeuralNetworks.graph-Tuple{FeaturedGraph}"><code>GraphNeuralNetworks.graph</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">graph(fg::FeaturedGraph)</code></pre><p>Return the underlying implementation of the graph structure of <code>fg</code>, either an adjacency matrix or an edge list in the COO format.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/featuredgraph.jl#L171-L176">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.message" href="#GraphNeuralNetworks.message"><code>GraphNeuralNetworks.message</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">message(mp::MessagePassing, x_i, x_j, [e_ij, u])</code></pre><p>Message function for the message-passing scheme, returning the message from node <code>j</code> to node <code>i</code> . In the message-passing scheme. the incoming messages  from the neighborhood of <code>i</code> will later be aggregated in order to <a href="#GraphNeuralNetworks.update"><code>update</code></a> the features of node <code>i</code>.</p><p>By default, the function returns <code>x_j</code>. Layers subtyping <a href="#GraphNeuralNetworks.MessagePassing"><code>MessagePassing</code></a> should  specialize this method with custom behavior.</p><p><strong>Arguments</strong></p><ul><li><code>mp</code>: A <a href="#GraphNeuralNetworks.MessagePassing"><code>MessagePassing</code></a> layer.</li><li><code>x_i</code>: Features of the central node <code>i</code>.</li><li><code>x_j</code>: Features of the neighbor <code>j</code> of node <code>i</code>.</li><li><code>e_ij</code>: Features of edge (<code>i</code>, <code>j</code>).</li><li><code>u</code>: Global features.</li></ul><p>See also <a href="#GraphNeuralNetworks.update"><code>update</code></a> and <a href="#GraphNeuralNetworks.propagate"><code>propagate</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/msgpass.jl#L64-L86">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.node_feature-Tuple{FeaturedGraph}" href="#GraphNeuralNetworks.node_feature-Tuple{FeaturedGraph}"><code>GraphNeuralNetworks.node_feature</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">node_feature(fg::FeaturedGraph)</code></pre><p>Return the node features of <code>fg</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/featuredgraph.jl#L261-L265">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.normalized_laplacian" href="#GraphNeuralNetworks.normalized_laplacian"><code>GraphNeuralNetworks.normalized_laplacian</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">normalized_laplacian(fg, T=Float32; add_self_loops=false, dir=:out)</code></pre><p>Normalized Laplacian matrix of graph <code>g</code>.</p><p><strong>Arguments</strong></p><ul><li><code>fg</code>: A <code>FeaturedGraph</code>.</li><li><code>T</code>: result element type.</li><li><code>add_self_loops</code>: add self-loops while calculating the matrix.</li><li><code>dir</code>: the edge directionality considered (:out, :in, :both).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/featuredgraph.jl#L300-L311">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.propagate" href="#GraphNeuralNetworks.propagate"><code>GraphNeuralNetworks.propagate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">propagate(mp::MessagePassing, fg::FeaturedGraph, aggr)
propagate(mp::MessagePassing, fg::FeaturedGraph, E, X, u, aggr)</code></pre><p>Perform the sequence of operation implementing the message-passing scheme and updating node, edge, and global features <code>X</code>, <code>E</code>, and <code>u</code> respectively.</p><p>The computation involved is the following:</p><pre><code class="language-julia hljs">M = compute_batch_message(mp, fg, E, X, u) 
E = update_edge(mp, M, E, u)
M̄ = aggregate_neighbors(mp, aggr, fg, M)
X = update(mp, M̄, X, u)
u = update_global(mp, E, X, u)</code></pre><p>Custom layers sub-typing <a href="#GraphNeuralNetworks.MessagePassing"><code>MessagePassing</code></a> typically call define their own <a href="#GraphNeuralNetworks.update"><code>update</code></a> and <a href="#GraphNeuralNetworks.message"><code>message</code></a> function, than call this method in the forward pass:</p><pre><code class="language-julia hljs">function (l::GNNLayer)(fg, X)
    ... some prepocessing if needed ...
    E = nothing
    u = nothing
    propagate(l, fg, E, X, u, +)
end</code></pre><p>See also <a href="#GraphNeuralNetworks.message"><code>message</code></a> and <a href="#GraphNeuralNetworks.update"><code>update</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/msgpass.jl#L13-L45">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.scaled_laplacian" href="#GraphNeuralNetworks.scaled_laplacian"><code>GraphNeuralNetworks.scaled_laplacian</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">scaled_laplacian(fg, T=Float32; dir=:out)</code></pre><p>Scaled Laplacian matrix of graph <code>g</code>, defined as <span>$\hat{L} = \frac{2}{\lambda_{max}} L - I$</span> where <span>$L$</span> is the normalized Laplacian matrix.</p><p><strong>Arguments</strong></p><ul><li><code>fg</code>: A <code>FeaturedGraph</code>.</li><li><code>T</code>: result element type.</li><li><code>dir</code>: the edge directionality considered (:out, :in, :both).</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/featuredgraph.jl#L329-L340">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="GraphNeuralNetworks.update" href="#GraphNeuralNetworks.update"><code>GraphNeuralNetworks.update</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">update(mp::MessagePassing, m̄, x, [u])</code></pre><p>Update function for the message-passing scheme, returning a new set of node features <code>x′</code> based on old  features <code>x</code> and the incoming message from the neighborhood aggregation <code>m̄</code>.</p><p>By default, the function returns <code>m̄</code>. Layers subtyping <a href="#GraphNeuralNetworks.MessagePassing"><code>MessagePassing</code></a> should  specialize this method with custom behavior.</p><p><strong>Arguments</strong></p><ul><li><code>mp</code>: A <a href="#GraphNeuralNetworks.MessagePassing"><code>MessagePassing</code></a> layer.</li><li><code>m̄</code>: Aggregated edge messages from the <a href="#GraphNeuralNetworks.message"><code>message</code></a> function.</li><li><code>x</code>: Node features to be updated.</li><li><code>u</code>: Global features.</li></ul><p>See also <a href="#GraphNeuralNetworks.message"><code>message</code></a> and <a href="#GraphNeuralNetworks.propagate"><code>propagate</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/c0b30e27e075fed546860e01d7ca719fd6af7c27/src/layers/msgpass.jl#L89-L109">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="dev/">Developer Notes »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.5 on <span class="colophon-date" title="Tuesday 31 August 2021 00:12">Tuesday 31 August 2021</span>. Using Julia version 1.6.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
