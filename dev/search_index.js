var documenterSearchIndex = {"docs":
[{"location":"api/gnngraph/","page":"GNNGraph","title":"GNNGraph","text":"CurrentModule = GraphNeuralNetworks","category":"page"},{"location":"api/gnngraph/#GNNGraph","page":"GNNGraph","title":"GNNGraph","text":"","category":"section"},{"location":"api/gnngraph/","page":"GNNGraph","title":"GNNGraph","text":"Documentation page for the graph type GNNGraph provided GraphNeuralNetworks.jl and its related methods. ","category":"page"},{"location":"api/gnngraph/#Index","page":"GNNGraph","title":"Index","text":"","category":"section"},{"location":"api/gnngraph/","page":"GNNGraph","title":"GNNGraph","text":"Order = [:type, :function]\nPages   = [\"gnngraph.md\"]","category":"page"},{"location":"api/gnngraph/#Docs","page":"GNNGraph","title":"Docs","text":"","category":"section"},{"location":"api/gnngraph/","page":"GNNGraph","title":"GNNGraph","text":"Modules = [GraphNeuralNetworks]\nPages   = [\"gnngraph.jl\"]\nPrivate = false","category":"page"},{"location":"api/gnngraph/#GraphNeuralNetworks.GNNGraph","page":"GNNGraph","title":"GraphNeuralNetworks.GNNGraph","text":"GNNGraph(data; [graph_type, ndata, edata, gdata, num_nodes, graph_indicator, dir])\nGNNGraph(g::GNNGraph; [ndata, edata, gdata])\n\nA type representing a graph structure and storing also  feature arrays associated to nodes, edges, and to the whole graph (global features). \n\nA GNNGraph can be constructed out of different objects data expressing the connections inside the graph. The internal representation type is determined by graph_type.\n\nWhen constructed from another GNNGraph, the internal graph representation is preserved and shared. The node/edge/global features are transmitted as well, unless explicitely changed though keyword arguments.\n\nA GNNGraph can also represent multiple graphs batched togheter  (see Flux.batch or SparseArrays.blockdiag). The field g.graph_indicator contains the graph membership of each node.\n\nA GNNGraph is a LightGraphs' AbstractGraph, therefore any functionality from the LightGraphs' graph library can be used on it.\n\nArguments\n\ndata: Some data representing the graph topology. Possible type are \nAn adjacency matrix\nAn adjacency list.\nA tuple containing the source and target vectors (COO representation)\nA LightGraphs' graph.\ngraph_type: A keyword argument that specifies                the underlying representation used by the GNNGraph.                Currently supported values are \n:coo. Graph represented as a tuple (source, target), such that the k-th edge          connects the node source[k] to node target[k].         Optionally, also edge weights can be given: (source, target, weights).\n:sparse. A sparse adjacency matrix representation.\n:dense. A dense adjacency matrix representation.  \nDefault :coo.\ndir. The assumed edge direction when given adjacency matrix or adjacency list input data g.        Possible values are :out and :in. Default :out.\nnum_nodes. The number of nodes. If not specified, inferred from g. Default nothing.\ngraph_indicator. For batched graphs, a vector containing the graph assigment of each node. Default nothing.  \nndata: Node features. A named tuple of arrays whose last dimension has size num_nodes.\nedata: Edge features. A named tuple of arrays whose whose last dimension has size num_edges.\ngdata: Global features. A named tuple of arrays whose has size num_graphs. \n\nUsage.\n\nusing Flux, GraphNeuralNetworks\n\n# Construct from adjacency list representation\ndata = [[2,3], [1,4,5], [1], [2,5], [2,4]]\ng = GNNGraph(data)\n\n# Number of nodes, edges, and batched graphs\ng.num_nodes  # 5\ng.num_edges  # 10 \ng.num_graphs # 1 \n\n# Same graph in COO representation\ns = [1,1,2,2,2,3,4,4,5,5]\nt = [2,3,1,4,5,3,2,5,2,4]\ng = GNNGraph(s, t)\n\n# From a LightGraphs' graph\ng = GNNGraph(erdos_renyi(100, 20))\n\n# Add 2 node feature arrays\ng = GNNGraph(g, ndata = (x=rand(100, g.num_nodes), y=rand(g.num_nodes)))\n\n# Add node features and edge features with default names `x` and `e` \ng = GNNGraph(g, ndata = rand(100, g.num_nodes), edata = rand(16, g.num_edges))\n\ng.ndata.x\ng.ndata.e\n\n# Send to gpu\ng = g |> gpu\n\n# Collect edges' source and target nodes.\n# Both source and target are vectors of length num_edges\nsource, target = edge_index(g)\n\n\n\n\n\n","category":"type"},{"location":"api/gnngraph/#GraphNeuralNetworks.add_self_loops-Tuple{GNNGraph{var\"#s15\"} where var\"#s15\"<:(Tuple{T, T, V} where {T<:(AbstractVector{T} where T), V})}","page":"GNNGraph","title":"GraphNeuralNetworks.add_self_loops","text":"add_self_loops(g::GNNGraph)\n\nReturn a graph with the same features as g but also adding edges connecting the nodes to themselves.\n\nNodes with already existing self-loops will obtain a second self-loop.\n\n\n\n\n\n","category":"method"},{"location":"api/gnngraph/#GraphNeuralNetworks.adjacency_list-Tuple{GNNGraph}","page":"GNNGraph","title":"GraphNeuralNetworks.adjacency_list","text":"adjacency_list(g; dir=:out)\n\nReturn the adjacency list representation (a vector of vectors) of the graph g.\n\nCalling a the adjacency list, if dir=:out a[i] will contain the neighbors of node i through outgoing edges. If dir=:in, it will contain neighbors from incoming edges instead.\n\n\n\n\n\n","category":"method"},{"location":"api/gnngraph/#GraphNeuralNetworks.edge_index-Tuple{GNNGraph{var\"#s16\"} where var\"#s16\"<:(Tuple{T, T, V} where {T<:(AbstractVector{T} where T), V})}","page":"GNNGraph","title":"GraphNeuralNetworks.edge_index","text":"edge_index(g::GNNGraph)\n\nReturn a tuple containing two vectors, respectively storing  the source and target nodes for each edges in g.\n\ns, t = edge_index(g)\n\n\n\n\n\n","category":"method"},{"location":"api/gnngraph/#GraphNeuralNetworks.getgraph-Tuple{GNNGraph, Int64}","page":"GNNGraph","title":"GraphNeuralNetworks.getgraph","text":"getgraph(g::GNNGraph, i)\n\nReturn the getgraph of g induced by those nodes v for which g.graph_indicator[v] ∈ i. In other words, it extract the component graphs from a batched graph. \n\nIt also returns a vector nodes mapping the new nodes to the old ones.  The node i in the getgraph corresponds to the node nodes[i] in g.\n\n\n\n\n\n","category":"method"},{"location":"api/gnngraph/#GraphNeuralNetworks.normalized_laplacian","page":"GNNGraph","title":"GraphNeuralNetworks.normalized_laplacian","text":"normalized_laplacian(g, T=Float32; add_self_loops=false, dir=:out)\n\nNormalized Laplacian matrix of graph g.\n\nArguments\n\ng: A GNNGraph.\nT: result element type.\nadd_self_loops: add self-loops while calculating the matrix.\ndir: the edge directionality considered (:out, :in, :both).\n\n\n\n\n\n","category":"function"},{"location":"api/gnngraph/#GraphNeuralNetworks.scaled_laplacian","page":"GNNGraph","title":"GraphNeuralNetworks.scaled_laplacian","text":"scaled_laplacian(g, T=Float32; dir=:out)\n\nScaled Laplacian matrix of graph g, defined as hatL = frac2lambda_max L - I where L is the normalized Laplacian matrix.\n\nArguments\n\ng: A GNNGraph.\nT: result element type.\ndir: the edge directionality considered (:out, :in, :both).\n\n\n\n\n\n","category":"function"},{"location":"api/gnngraph/","page":"GNNGraph","title":"GNNGraph","text":"Flux.batch\nSparseArrays.blockdiag\nLightGraphs.adjacency_matrix","category":"page"},{"location":"api/gnngraph/#Flux.batch","page":"GNNGraph","title":"Flux.batch","text":"batch(xs::Vector{<:GNNGraph})\n\nBatch together multiple GNNGraphs into a single one  containing the total number of nodes and edges of the original graphs.\n\nEquivalent to SparseArrays.blockdiag.\n\n\n\n\n\nbatch(xs)\n\nBatch the arrays in xs into a single array.\n\nExamples\n\njulia> Flux.batch([[1,2,3],[4,5,6]])\n3×2 Matrix{Int64}:\n 1  4\n 2  5\n 3  6\n\n\n\n\n\n","category":"function"},{"location":"api/gnngraph/#SparseArrays.blockdiag","page":"GNNGraph","title":"SparseArrays.blockdiag","text":"blockdiag(A...)\n\nConcatenate matrices block-diagonally. Currently only implemented for sparse matrices.\n\nExamples\n\njulia> blockdiag(sparse(2I, 3, 3), sparse(4I, 2, 2))\n5×5 SparseMatrixCSC{Int64, Int64} with 5 stored entries:\n 2  ⋅  ⋅  ⋅  ⋅\n ⋅  2  ⋅  ⋅  ⋅\n ⋅  ⋅  2  ⋅  ⋅\n ⋅  ⋅  ⋅  4  ⋅\n ⋅  ⋅  ⋅  ⋅  4\n\n\n\n\n\nblockdiag(g, h)\n\nReturn a graph with V(g) + V(h) vertices and E(g) + E(h) edges where the vertices and edges from graph h are appended to graph g.\n\nImplementation Notes\n\nPreserves the eltype of the input graph. Will error if the number of vertices in the generated graph exceeds the eltype.\n\nExamples\n\njulia> g1 = SimpleDiGraph([0 1 0 0 0; 0 0 1 0 0; 1 0 0 1 0; 0 0 0 0 1; 0 0 0 1 0]);\n\njulia> g2 = SimpleDiGraph([0 1 0; 0 0 1; 1 0 0]);\n\njulia> blockdiag(g1, g2)\n{8, 9} directed simple Int64 graph\n\njulia> foreach(println, edges(blockdiag(g1, g2)))\nEdge 1 => 2\nEdge 2 => 3\nEdge 3 => 1\nEdge 3 => 4\nEdge 4 => 5\nEdge 5 => 4\nEdge 6 => 7\nEdge 7 => 8\nEdge 8 => 6\n\n\n\n\n\nblockdiag(xs::GNNGraph...)\n\nEquivalent to Flux.batch.\n\n\n\n\n\n","category":"function"},{"location":"api/gnngraph/#LightGraphs.LinAlg.adjacency_matrix","page":"GNNGraph","title":"LightGraphs.LinAlg.adjacency_matrix","text":"adjacency_matrix(g[, T=Int; dir=:out])\n\nReturn a sparse adjacency matrix for a graph, indexed by [u, v] vertices. Non-zero values indicate an edge from u to v. Users may override the default data type (Int) and specify an optional direction.\n\nOptional Arguments\n\ndir=:out: :in, :out, or :both are currently supported.\n\nImplementation Notes\n\nThis function is optimized for speed and directly manipulates CSC sparse matrix fields.\n\n\n\n\n\n","category":"function"},{"location":"dev/#Developer-Notes","page":"Developer Notes","title":"Developer Notes","text":"","category":"section"},{"location":"dev/#Benchmarking","page":"Developer Notes","title":"Benchmarking","text":"","category":"section"},{"location":"dev/","page":"Developer Notes","title":"Developer Notes","text":"You can benchmark the effect on performance of your commits using the script perf/perf.jl.","category":"page"},{"location":"dev/","page":"Developer Notes","title":"Developer Notes","text":"First, checkout and benchmark the master branch:","category":"page"},{"location":"dev/","page":"Developer Notes","title":"Developer Notes","text":"julia> include(\"perf.jl\")\n\njulia> df = run_benchmarks()\n\n# observe results\njulia> for g in groupby(df, :layer); println(g, \"\\n\"); end\n\njulia> @save \"perf_master_20210803_mymachine.jld2\" dfmaster=df","category":"page"},{"location":"dev/","page":"Developer Notes","title":"Developer Notes","text":"Now checkout your branch and do the same:","category":"page"},{"location":"dev/","page":"Developer Notes","title":"Developer Notes","text":"julia> df = run_benchmarks()\n\njulia> @save \"perf_pr_20210803_mymachine.jld2\" dfpr=df","category":"page"},{"location":"dev/","page":"Developer Notes","title":"Developer Notes","text":"Finally, compare the results:","category":"page"},{"location":"dev/","page":"Developer Notes","title":"Developer Notes","text":"julia> @load \"perf_master_20210803_mymachine.jld2\"\n\njulia> @load \"perf_pr_20210803_mymachine.jld2\"\n\njulia> compare(dfpr, dfmaster)","category":"page"},{"location":"gnngraph/#Graphs","page":"Graphs","title":"Graphs","text":"","category":"section"},{"location":"gnngraph/","page":"Graphs","title":"Graphs","text":"The fundamental graph type in GraphNeuralNetworks.jl is the GNNGraph,  A GNNGraph g is a directed graph with nodes labeled from 1 to g.num_nodes. The underlying implementation allows for efficient application of graph neural network operators, gpu movement, and storage of node/edge/graph related feature arrays.","category":"page"},{"location":"gnngraph/#Graph-Creation","page":"Graphs","title":"Graph Creation","text":"","category":"section"},{"location":"gnngraph/","page":"Graphs","title":"Graphs","text":"A GNNGraph can be created from several different data sources encoding the graph topology:","category":"page"},{"location":"gnngraph/","page":"Graphs","title":"Graphs","text":"using GraphNeuralNetworks, LightGraphs, SparseArrays\n\n\n# Construct GNNGraph from From LightGraphs's graph\nlg = erdos_renyi(10, 30)\ng = GNNGraph(lg)\n\n# From an adjacency matrix\nA = sprand(10, 10, 0.3)\ng = GNNGraph(A)\n\n# From an adjacency list\nadjlist = [[2,3], [1,3], [1,2,4], [3]]\ng = GNNGraph(adjlist)\n\n# From COO representation\nsource = [1,1,2,2,3,3,3,4]\ntarget = [2,3,1,3,1,2,4,3]\ng = GNNGraph(source, target)","category":"page"},{"location":"gnngraph/","page":"Graphs","title":"Graphs","text":"See also the related methods adjacency_matrix, edge_index, and adjacency_list.","category":"page"},{"location":"gnngraph/#Data-Features","page":"Graphs","title":"Data Features","text":"","category":"section"},{"location":"gnngraph/","page":"Graphs","title":"Graphs","text":"# Create a graph with a single feature array `x` associated to nodes\ng = GNNGraph(erdos_renyi(10,  30), ndata = (; x = rand(Float32, 32, 10)))\n# Equivalent definition\ng = GNNGraph(erdos_renyi(10,  30), ndata = rand(Float32, 32, 10))\n\n# You can have multiple feature arrays\ng = GNNGraph(erdos_renyi(10,  30), ndata = (; x=rand(Float32, 32, 10), y=rand(Float32, 10)))\n\n\n# Attach an array with edge features.\n# Since `GNNGraph`s are directed, the number of edges\n# will be double that of the original LightGraphs' undirected graph.\ng = GNNGraph(erdos_renyi(10,  30), edata = rand(Float32, 60))\n@assert g.num_edges == 60\n\n# If we pass only half of the edge features, they will be copied\n# on the reversed edges.\ng = GNNGraph(erdos_renyi(10,  30), edata = rand(Float32, 30))\n\n\n# Create a new graph from previous one, inheriting edge data\n# but replacing node data\ng′ = GNNGraph(g, ndata =(; z = ones(Float32, 16, 10)))","category":"page"},{"location":"gnngraph/#Graph-Manipulation","page":"Graphs","title":"Graph Manipulation","text":"","category":"section"},{"location":"gnngraph/","page":"Graphs","title":"Graphs","text":"g′ = add_self_loops(g)\n\ng′ = remove_self_loops(g)","category":"page"},{"location":"gnngraph/#Batches-and-Subgraphs","page":"Graphs","title":"Batches and Subgraphs","text":"","category":"section"},{"location":"gnngraph/","page":"Graphs","title":"Graphs","text":"using Flux\n\ngall = Flux.batch([GNNGraph(erdos_renyi(10, 30), ndata=rand(Float32,3,10)) for _ in 1:160])\n\ng23 = getgraph(gall, 2:3)\n@assert g23.num_graphs == 2\n@assert g23.num_nodes == 20\n@assert g23.num_edges == 120 # 30 undirected edges x 2 graphs\n\n\n# DataLoader compatibility\ntrain_loader = Flux.Data.DataLoader(gall, batchsize=16, shuffle=true)\n\nfor g in train_loader\n    @assert g.num_graphs == 16\n    @assert g.num_nodes == 160\n    @assert size(g.ndata.x) = (3, 160)    \n    .....\nend","category":"page"},{"location":"gnngraph/#JuliaGraphs-ecosystem-integration","page":"Graphs","title":"JuliaGraphs ecosystem integration","text":"","category":"section"},{"location":"gnngraph/","page":"Graphs","title":"Graphs","text":"Since GNNGraph <: LightGraphs.AbstractGraph, we can use any functionality from LightGraphs. ","category":"page"},{"location":"gnngraph/","page":"Graphs","title":"Graphs","text":"@assert LightGraphs.isdirected(g)","category":"page"},{"location":"gnngraph/#GPU-movement","page":"Graphs","title":"GPU movement","text":"","category":"section"},{"location":"gnngraph/","page":"Graphs","title":"Graphs","text":"Move a GNNGraph to a CUDA device using Flux.gpu method. ","category":"page"},{"location":"gnngraph/","page":"Graphs","title":"Graphs","text":"using Flux: gpu\n\ng_gpu = g |> gpu","category":"page"},{"location":"models/#Models","page":"Model Building","title":"Models","text":"","category":"section"},{"location":"models/","page":"Model Building","title":"Model Building","text":"GraphNeuralNetworks.jl provides common graph convolutional layers by which you can assemble arbitrarily deep or complex models. GNN layers are compatible with  Flux.jl ones, therefore expert Flux's users should be immediately able to define and train  their models. ","category":"page"},{"location":"models/","page":"Model Building","title":"Model Building","text":"In what follows, we discuss two different styles for model creation: the explicit modeling style, more verbose but more flexible,  and the implicit modeling style based on GNNChain, more concise but less flexible.","category":"page"},{"location":"models/#Explicit-modeling","page":"Model Building","title":"Explicit modeling","text":"","category":"section"},{"location":"models/","page":"Model Building","title":"Model Building","text":"In the explicit modeling style, the model is created according to the following steps:","category":"page"},{"location":"models/","page":"Model Building","title":"Model Building","text":"Define a new type for your model (GNN in the example below). Layers and submodels are fields.\nApply Flux.@functor to the new type to make it Flux's compatible (parameters' collection, gpu movement, etc...)\nOptionally define a convenience constructor for your model.\nDefine the forward pass by implementing the function call method for your type\nInstantiate the model. ","category":"page"},{"location":"models/","page":"Model Building","title":"Model Building","text":"Here is an example of this construction:","category":"page"},{"location":"models/","page":"Model Building","title":"Model Building","text":"using Flux, LightGraphs, GraphNeuralNetworks\nusing Flux: @functor\n\nstruct GNN                                # step 1\n    conv1\n    bn\n    conv2\n    dropout\n    dense\nend\n\n@functor GNN                              # step 2\n\nfunction GNN(din::Int, d::Int, dout::Int) # step 3    \n    GNN(GCNConv(din => d),\n        BatchNorm(d),\n        GraphConv(d => d, relu),\n        Dropout(0.5),\n        Dense(d, dout))\nend\n\nfunction (model::GNN)(g::GNNGraph, x)     # step 4\n    x = model.conv1(g, x)\n    x = relu.(model.bn(x))\n    x = model.conv2(g, x)\n    x = model.dropout(x)\n    x = model.dense(x)\n    return x \nend\n\ndin, d, dout = 3, 4, 2 \ng = GNNGraph(random_regular_graph(10, 4))\nX = randn(Float32, din, 10)\nmodel = GNN(din, d, dout)                 # step 5\ny = model(g, X)","category":"page"},{"location":"models/#Implicit-modeling-with-GNNChains","page":"Model Building","title":"Implicit modeling with GNNChains","text":"","category":"section"},{"location":"models/","page":"Model Building","title":"Model Building","text":"While very flexible, the way in which we defined GNN model definition in last section is a bit verbose. In order to simplify things, we provide the GNNChain type. It is very similar  to Flux's well known Chain. It allows to compose layers in a sequential fashion as Chain does, propagating the output of each layer to the next one. In addition, GNNChain  handles propagates the input graph as well, providing it as a first argument to layers subtyping the GNNLayer abstract type. ","category":"page"},{"location":"models/","page":"Model Building","title":"Model Building","text":"Using GNNChain, the previous example becomes","category":"page"},{"location":"models/","page":"Model Building","title":"Model Building","text":"using Flux, LightGraphs, GraphNeuralNetworks\n\ndin, d, dout = 3, 4, 2 \ng = GNNGraph(random_regular_graph(10, 4))\nX = randn(Float32, din, 10)\n\nmodel = GNNChain(GCNConv(din => d),\n                 BatchNorm(d),\n                 x -> relu.(x),\n                 GraphConv(d => d, relu),\n                 Dropout(0.5),\n                 Dense(d, dout))\n\ny = model(g, X)","category":"page"},{"location":"models/","page":"Model Building","title":"Model Building","text":"The GNNChain only propagates the graph and the node features. More complex scenarios, e.g. when also edge features are updated, have to be handled using the explicit definition of the forward pass. ","category":"page"},{"location":"api/pool/","page":"Pooling Layers","title":"Pooling Layers","text":"CurrentModule = GraphNeuralNetworks","category":"page"},{"location":"api/pool/#Pooling-Layers","page":"Pooling Layers","title":"Pooling Layers","text":"","category":"section"},{"location":"api/pool/#Index","page":"Pooling Layers","title":"Index","text":"","category":"section"},{"location":"api/pool/","page":"Pooling Layers","title":"Pooling Layers","text":"Order = [:type, :function]\nPages   = [\"pool.md\"]","category":"page"},{"location":"api/pool/#Docs","page":"Pooling Layers","title":"Docs","text":"","category":"section"},{"location":"api/pool/","page":"Pooling Layers","title":"Pooling Layers","text":"Modules = [GraphNeuralNetworks]\nPages   = [\"layers/pool.jl\"]\nPrivate = false","category":"page"},{"location":"api/pool/#GraphNeuralNetworks.GlobalPool","page":"Pooling Layers","title":"GraphNeuralNetworks.GlobalPool","text":"GlobalPool(aggr)\n\nGlobal pooling layer for graph neural networks. Takes a graph and feature nodes as inputs and performs the operation\n\nmathbfu_V = square_i in V mathbfx_i\n\nwhere V is the set of nodes of the input graph and  the type of aggregation represented by square is selected by the aggr argument.  Commonly used aggregations are mean, max, and +.\n\nusing Flux, GraphNeuralNetworks, LightGraphs\n\npool = GlobalPool(mean)\n\ng = GNNGraph(erdos_renyi(10, 4))\nX = rand(32, 10)\npool(g, X) # => 32x1 matrix\n\n\ng = Flux.batch([GNNGraph(erdos_renyi(10, 4)) for _ in 1:5])\nX = rand(32, 50)\npool(g, X) # => 32x5 matrix\n\n\n\n\n\n","category":"type"},{"location":"api/pool/#GraphNeuralNetworks.TopKPool","page":"Pooling Layers","title":"GraphNeuralNetworks.TopKPool","text":"TopKPool(adj, k, in_channel)\n\nTop-k pooling layer.\n\nArguments\n\nadj: Adjacency matrix  of a graph.\nk: Top-k nodes are selected to pool together.\nin_channel: The dimension of input channel.\n\n\n\n\n\n","category":"type"},{"location":"messagepassing/#Message-Passing","page":"Message Passing","title":"Message Passing","text":"","category":"section"},{"location":"messagepassing/","page":"Message Passing","title":"Message Passing","text":"The message passing is initiated by propagate and can be customized for a specific layer by overloading the methods compute_message, update_node, and update_edge.","category":"page"},{"location":"messagepassing/","page":"Message Passing","title":"Message Passing","text":"The message passing corresponds to the following operations ","category":"page"},{"location":"messagepassing/","page":"Message Passing","title":"Message Passing","text":"beginaligned\nmathbfm_jto i = phi(mathbfx_i mathbfx_j mathbfe_jto i) \nmathbfx_i = gamma_x(mathbfx_i square_jin N(i)  mathbfm_jto i)\nmathbfe_jto i^prime =  gamma_e(mathbfe_j to imathbfm_j to i)\nendaligned","category":"page"},{"location":"messagepassing/","page":"Message Passing","title":"Message Passing","text":"where phi is expressed by the compute_message function,  gamma_x and gamma_e by update_node and update_edge respectively.","category":"page"},{"location":"messagepassing/","page":"Message Passing","title":"Message Passing","text":"The message propagation mechanism internally relies on the NNlib.gather  and NNlib.scatter methods.","category":"page"},{"location":"messagepassing/#An-example:-implementing-the-GCNConv","page":"Message Passing","title":"An example: implementing the GCNConv","text":"","category":"section"},{"location":"messagepassing/","page":"Message Passing","title":"Message Passing","text":"Let's (re-)implement the GCNConv layer use the message passing framework. The convolution reads ","category":"page"},{"location":"messagepassing/","page":"Message Passing","title":"Message Passing","text":"mathbfx_i = sum_j in N(i) frac1c_ij W mathbfx_j","category":"page"},{"location":"messagepassing/","page":"Message Passing","title":"Message Passing","text":"where c_ij = sqrtN(i)N(j). We will also add a bias and an activation function.","category":"page"},{"location":"messagepassing/","page":"Message Passing","title":"Message Passing","text":"using Flux, LightGraphs, GraphNeuralNetworks\nimport GraphNeuralNetworks: compute_message, update_node, propagate\n\nstruct GCN{A<:AbstractMatrix, B, F} <: GNNLayer\n    weight::A\n    bias::B\n    σ::F\nend\n\nFlux.@functor GCN # allow collecting params, gpu movement, etc...\n\nfunction GCN(ch::Pair{Int,Int}, σ=identity)\n    in, out = ch\n    W = Flux.glorot_uniform(out, in)\n    b = zeros(Float32, out)\n    GCN(W, b, σ)\nend\n\ncompute_message(l::GCN, xi, xj, eij) = l.weight * xj\nupdate_node(l::GCN, m, x) = m\n\nfunction (l::GCN)(g::GNNGraph, x::AbstractMatrix{T}) where T\n    c = 1 ./ sqrt.(degree(g, T, dir=:in))\n    x = x .* c'\n    x, _ = propagate(l, g, +, x)\n    x = x .* c'\n    return l.σ.(x .+ l.bias)\nend","category":"page"},{"location":"messagepassing/","page":"Message Passing","title":"Message Passing","text":"See the GATConv implementation here for a more complex example.","category":"page"},{"location":"api/basic/","page":"Basic Layers","title":"Basic Layers","text":"CurrentModule = GraphNeuralNetworks","category":"page"},{"location":"api/basic/#Basic-Layers","page":"Basic Layers","title":"Basic Layers","text":"","category":"section"},{"location":"api/basic/#Index","page":"Basic Layers","title":"Index","text":"","category":"section"},{"location":"api/basic/","page":"Basic Layers","title":"Basic Layers","text":"Order = [:type, :function]\nModules = [GraphNeuralNetworks]\nPages = [\"basic.md\"]","category":"page"},{"location":"api/basic/#Docs","page":"Basic Layers","title":"Docs","text":"","category":"section"},{"location":"api/basic/","page":"Basic Layers","title":"Basic Layers","text":"GNNLayer\nGNNChain","category":"page"},{"location":"api/basic/#GraphNeuralNetworks.GNNLayer","page":"Basic Layers","title":"GraphNeuralNetworks.GNNLayer","text":"abstract type GNNLayer end\n\nAn abstract type from which graph neural network layers are derived.\n\nSee also GNNChain.\n\n\n\n\n\n","category":"type"},{"location":"api/basic/#GraphNeuralNetworks.GNNChain","page":"Basic Layers","title":"GraphNeuralNetworks.GNNChain","text":"GNNChain(layers...)\nGNNChain(name = layer, ...)\n\nCollects multiple layers / functions to be called in sequence on given input graph and input node features. \n\nIt allows to compose layers in a sequential fashion as Flux.Chain does, propagating the output of each layer to the next one. In addition, GNNChain handles the input graph as well, providing it  as a first argument only to layers subtyping the GNNLayer abstract type. \n\nGNNChain supports indexing and slicing, m[2] or m[1:end-1], and if names are given, m[:name] == m[1] etc.\n\nExamples\n\njulia> m = GNNChain(GCNConv(2=>5), BatchNorm(5), x -> relu.(x), Dense(5, 4));\n\njulia> x = randn(Float32, 2, 3);\n\njulia> g = GNNGraph([1,1,2,3], [2,3,1,1]);\n\njulia> m(g, x)\n4×3 Matrix{Float32}:\n  0.157941    0.15443     0.193471\n  0.0819516   0.0503105   0.122523\n  0.225933    0.267901    0.241878\n -0.0134364  -0.0120716  -0.0172505\n\n\n\n\n\n","category":"type"},{"location":"api/conv/","page":"Convolutional Layers","title":"Convolutional Layers","text":"CurrentModule = GraphNeuralNetworks","category":"page"},{"location":"api/conv/#Convolutional-Layers","page":"Convolutional Layers","title":"Convolutional Layers","text":"","category":"section"},{"location":"api/conv/#Index","page":"Convolutional Layers","title":"Index","text":"","category":"section"},{"location":"api/conv/","page":"Convolutional Layers","title":"Convolutional Layers","text":"Order = [:type, :function]\nPages = [\"conv.md\"]","category":"page"},{"location":"api/conv/#Docs","page":"Convolutional Layers","title":"Docs","text":"","category":"section"},{"location":"api/conv/","page":"Convolutional Layers","title":"Convolutional Layers","text":"Modules = [GraphNeuralNetworks]\nPages   = [\"layers/conv.jl\"]\nPrivate = false","category":"page"},{"location":"api/conv/#GraphNeuralNetworks.ChebConv","page":"Convolutional Layers","title":"GraphNeuralNetworks.ChebConv","text":"ChebConv(in => out, k; bias=true, init=glorot_uniform)\n\nChebyshev spectral graph convolutional layer from paper Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering.\n\nImplements\n\nX = sum^K-1_k=0  W^(k) Z^(k)\n\nwhere Z^(k) is the k-th term of Chebyshev polynomials, and can be calculated by the following recursive form:\n\nZ^(0) = X \nZ^(1) = hatL X \nZ^(k) = 2 hatL Z^(k-1) - Z^(k-2)\n\nwith hatL the scaled_laplacian.\n\nArguments\n\nin: The dimension of input features.\nout: The dimension of output features.\nk: The order of Chebyshev polynomial.\nbias: Add learnable bias.\ninit: Weights' initializer.\n\n\n\n\n\n","category":"type"},{"location":"api/conv/#GraphNeuralNetworks.EdgeConv","page":"Convolutional Layers","title":"GraphNeuralNetworks.EdgeConv","text":"EdgeConv(nn; aggr=max)\n\nEdge convolutional layer from paper Dynamic Graph CNN for Learning on Point Clouds.\n\nPerforms the operation\n\nmathbfx_i = square_j in N(i) nn(mathbfx_i  mathbfx_j - mathbfx_i)\n\nwhere nn generally denotes a learnable function, e.g. a linear layer or a multi-layer perceptron.\n\nArguments\n\nnn: A (possibly learnable) function acting on edge features. \naggr: Aggregation operator for the incoming messages (e.g. +, *, max, min, and mean).\n\n\n\n\n\n","category":"type"},{"location":"api/conv/#GraphNeuralNetworks.GATConv","page":"Convolutional Layers","title":"GraphNeuralNetworks.GATConv","text":"GATConv(in => out, σ=identity;\n        heads=1,\n        concat=true,\n        init=glorot_uniform    \n        bias=true, \n        negative_slope=0.2f0)\n\nGraph attentional layer from the paper Graph Attention Networks.\n\nImplements the operation\n\nmathbfx_i = sum_j in N(i) alpha_ij W mathbfx_j\n\nwhere the attention coefficient alpha_ij is given by\n\nalpha_ij = frac1z_i exp(LeakyReLU(mathbfa^T W mathbfx_i  W mathbfx_j))\n\nwith z_i a normalization factor.\n\nArguments\n\nin: The dimension of input features.\nout: The dimension of output features.\nbias::Bool: Keyword argument, whether to learn the additive bias.\nheads: Number attention heads \nconcat: Concatenate layer output or not. If not, layer output is averaged over the heads.\nnegative_slope::Real: Keyword argument, the parameter of LeakyReLU.\n\n\n\n\n\n","category":"type"},{"location":"api/conv/#GraphNeuralNetworks.GCNConv","page":"Convolutional Layers","title":"GraphNeuralNetworks.GCNConv","text":"GCNConv(in => out, σ=identity; bias=true, init=glorot_uniform, add_self_loops=true)\n\nGraph convolutional layer from paper Semi-supervised Classification with Graph Convolutional Networks.\n\nPerforms the operation\n\nmathbfx_i = sum_jin N(i) frac1c_ij W mathbfx_j\n\nwhere c_ij = sqrtN(i)N(j).\n\nThe input to the layer is a node feature array X  of size (num_features, num_nodes).\n\nArguments\n\nin: Number of input features.\nout: Number of output features.\nσ: Activation function.\nbias: Add learnable bias.\ninit: Weights' initializer.\nadd_self_loops: Add self loops to the graph before performing the convolution.\n\n\n\n\n\n","category":"type"},{"location":"api/conv/#GraphNeuralNetworks.GINConv","page":"Convolutional Layers","title":"GraphNeuralNetworks.GINConv","text":"GINConv(f; eps = 0f0)\n\nGraph Isomorphism convolutional layer from paper How Powerful are Graph Neural Networks?\n\nmathbfx_i = f_Thetaleft((1 + epsilon) mathbfx_i + sum_j in N(i) mathbfx_j right)\n\nwhere f_Theta typically denotes a learnable function, e.g. a linear layer or a multi-layer perceptron.\n\nArguments\n\nf: A (possibly learnable) function acting on node features. \neps: Weighting factor.\n\n\n\n\n\n","category":"type"},{"location":"api/conv/#GraphNeuralNetworks.GatedGraphConv","page":"Convolutional Layers","title":"GraphNeuralNetworks.GatedGraphConv","text":"GatedGraphConv(out, num_layers; aggr=+, init=glorot_uniform)\n\nGated graph convolution layer from Gated Graph Sequence Neural Networks.\n\nImplements the recursion\n\nmathbfh^(0)_i = mathbfx_i  mathbf0 \nmathbfh^(l)_i = GRU(mathbfh^(l-1)_i square_j in N(i) W mathbfh^(l-1)_j)\n\nwhere mathbfh^(l)_i denotes the l-th hidden variables passing through GRU. The dimension of input mathbfx_i needs to be less or equal to out.\n\nArguments\n\nout: The dimension of output features.\nnum_layers: The number of gated recurrent unit.\naggr: Aggregation operator for the incoming messages (e.g. +, *, max, min, and mean).\ninit: Weight initialization function.\n\n\n\n\n\n","category":"type"},{"location":"api/conv/#GraphNeuralNetworks.GraphConv","page":"Convolutional Layers","title":"GraphNeuralNetworks.GraphConv","text":"GraphConv(in => out, σ=identity, aggr=+; bias=true, init=glorot_uniform)\n\nGraph convolution layer from Reference: Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks.\n\nPerforms:\n\nmathbfx_i = W_1 mathbfx_i + square_j in mathcalN(i) W_2 mathbfx_j\n\nwhere the aggregation type is selected by aggr.\n\nArguments\n\nin: The dimension of input features.\nout: The dimension of output features.\nσ: Activation function.\naggr: Aggregation operator for the incoming messages (e.g. +, *, max, min, and mean).\nbias: Add learnable bias.\ninit: Weights' initializer.\n\n\n\n\n\n","category":"type"},{"location":"api/conv/#GraphNeuralNetworks.NNConv","page":"Convolutional Layers","title":"GraphNeuralNetworks.NNConv","text":"NNConv(in => out, f, σ=identity; aggr=+, bias=true, init=glorot_uniform)\n\nThe continuous kernel-based convolutional operator from the  Neural Message Passing for Quantum Chemistry paper.  This convolution is also known as the edge-conditioned convolution from the  Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs paper.\n\nPerforms the operation\n\nmathbfx_i = W mathbfx_i + square_j in N(i) f_Theta(mathbfe_jto i)mathbfx_j\n\nwhere f_Theta  denotes a learnable function (e.g. a linear layer or a multi-layer perceptron). Given an input of batched edge features e of size (num_edge_features, num_edges),  the function f will return an batched matrices array whose size is (out, in, num_edges). For convenience, also functions returning a single (out*in, num_edges) matrix are allowed.\n\nArguments\n\nin: The dimension of input features.\nout: The dimension of output features.\nf: A (possibly learnable) function acting on edge features.\naggr: Aggregation operator for the incoming messages (e.g. +, *, max, min, and mean).\nσ: Activation function.\nbias: Add learnable bias.\ninit: Weights' initializer.\n\n\n\n\n\n","category":"type"},{"location":"api/messagepassing/","page":"Message Passing","title":"Message Passing","text":"CurrentModule = GraphNeuralNetworks","category":"page"},{"location":"api/messagepassing/#Message-Passing","page":"Message Passing","title":"Message Passing","text":"","category":"section"},{"location":"api/messagepassing/#Index","page":"Message Passing","title":"Index","text":"","category":"section"},{"location":"api/messagepassing/","page":"Message Passing","title":"Message Passing","text":"Order = [:type, :function]\nPages   = [\"messagepassing.md\"]","category":"page"},{"location":"api/messagepassing/#Docs","page":"Message Passing","title":"Docs","text":"","category":"section"},{"location":"api/messagepassing/","page":"Message Passing","title":"Message Passing","text":"compute_message\nupdate_node\nupdate_edge\npropagate","category":"page"},{"location":"api/messagepassing/#GraphNeuralNetworks.compute_message","page":"Message Passing","title":"GraphNeuralNetworks.compute_message","text":"compute_message(l, x_i, x_j, [e_ij])\n\nMessage function for the message-passing scheme started by propagate. Returns the message from node j to node i . In the message-passing scheme, the incoming messages  from the neighborhood of i will later be aggregated in order to update (see update_node) the features of node i.\n\nThe function operates on batches of edges, therefore x_i, x_j, and e_ij are tensors whose last dimension is the batch size, or can be tuple/namedtuples of  such tensors, according to the input to propagate.\n\nBy default, the function returns x_j. Custom layer should specialize this method with the desired behavior.\n\nArguments\n\nl: A gnn layer.\nx_i: Features of the central node i.\nx_j: Features of the neighbor j of node i.\ne_ij: Features of edge (i,j).\n\nSee also update_node and propagate.\n\n\n\n\n\n","category":"function"},{"location":"api/messagepassing/#GraphNeuralNetworks.update_node","page":"Message Passing","title":"GraphNeuralNetworks.update_node","text":"update_node(l, m̄, x)\n\nNode update function for the GNN layer l, returning a new set of node features x′ based on old  features x and the aggregated message m̄ from the neighborhood.\n\nThe input m̄ is an array, a tuple or a named tuple,  reflecting the output of compute_message.\n\nBy default, the function returns m̄. Custom layers should  specialize this method with the desired behavior.\n\nSee also compute_message, update_edge, and propagate.\n\n\n\n\n\n","category":"function"},{"location":"api/messagepassing/#GraphNeuralNetworks.update_edge","page":"Message Passing","title":"GraphNeuralNetworks.update_edge","text":"update_edge(l, m, e)\n\nEdge update function for the GNN layer l, returning a new set of edge features e′ based on old  features e and the newly computed messages m from the compute_message function.\n\nBy default, the function returns e. Custom layers should specialize this method with the desired behavior.\n\nSee also compute_message, update_node, and propagate.\n\n\n\n\n\n","category":"function"},{"location":"api/messagepassing/#GraphNeuralNetworks.propagate","page":"Message Passing","title":"GraphNeuralNetworks.propagate","text":"propagate(l, g, aggr, [x, e]) -> x′, e′\npropagate(l, g, aggr) -> g′\n\nPerforms the message-passing for GNN layer l on graph g .  Returns updated node and edge features x and e.\n\nIn case no input and edge features are given as input,  extracts them from g and returns the same graph with updated feautres.\n\nThe computational steps are the following:\n\nm = compute_batch_message(l, g, x, e)  # calls `compute_message`\nm̄ = aggregate_neighbors(g, aggr, m)\nx′ = update_node(l, m̄, x)\ne′ = update_edge(l, m, e)\n\nCustom layers typically define their own update_node and compute_message functions, then call this method in the forward pass:\n\nUsage example\n\nusing GraphNeuralNetworks, Flux\n\nstruct GNNConv <: GNNLayer\n    W\n    b\n    σ\nend\n\nFlux.@functor GNNConv\n\nfunction GNNConv(ch::Pair{Int,Int}, σ=identity;\n                 init=glorot_uniform, bias::Bool=true)\n    in, out = ch\n    W = init(out, in)\n    b = Flux.create_bias(W, bias, out)\n    GNNConv(W, b, σ, aggr)\nend\n\ncompute_message(l::GNNConv, x_i, x_j, e_ij) = l.W * x_j\nupdate_node(l::GNNConv, m̄, x) = l.σ.(m̄ .+ l.bias)\n\nfunction (l::GNNConv)(g::GNNGraph, x::AbstractMatrix)\n    x, _ = propagate(l, g, +, x)\n    return x\nend\n\nSee also compute_message and update_node.\n\n\n\n\n\n","category":"function"},{"location":"api/nnlib/","page":"NNlib","title":"NNlib","text":"CurrentModule = GraphNeuralNetworks","category":"page"},{"location":"api/nnlib/#NNlib","page":"NNlib","title":"NNlib","text":"","category":"section"},{"location":"api/nnlib/","page":"NNlib","title":"NNlib","text":"Primitive functions implemented in NNlib.jl.","category":"page"},{"location":"api/nnlib/#Index","page":"NNlib","title":"Index","text":"","category":"section"},{"location":"api/nnlib/","page":"NNlib","title":"NNlib","text":"Order = [:type, :function]\nPages   = [\"nnlib.md\"]","category":"page"},{"location":"api/nnlib/#Docs","page":"NNlib","title":"Docs","text":"","category":"section"},{"location":"api/nnlib/","page":"NNlib","title":"NNlib","text":"NNlib.gather!\nNNlib.gather\nNNlib.scatter!\nNNlib.scatter","category":"page"},{"location":"api/nnlib/#NNlib.gather!","page":"NNlib","title":"NNlib.gather!","text":"gather!(dst, src, idx)\n\nReverse operation of scatter!. Gathers data from source src  and writes it in destination dst according to the index array idx. For each k in CartesianIndices(idx), assign values to dst according to\n\ndst[:, ... , k] .= src[:, ... , idx[k]...]\n\nNotice that if idx is a vector containing integers, and both dst and src are matrices, previous expression simplifies to\n\ndst[:, k] .= src[:, idx[k]]\n\nand k will run over 1:length(idx). \n\nThe elements of idx can be integers or integer tuples and may be repeated.  A single src column can end up being copied into zero, one,  or multiple dst columns.\n\nSee gather for an allocating version.\n\n\n\n\n\n","category":"function"},{"location":"api/nnlib/#NNlib.gather","page":"NNlib","title":"NNlib.gather","text":"gather(src, idx) -> dst\n\nReverse operation of scatter. Gathers data from source src  and writes it in a destination dst according to the index array idx. For each k in CartesianIndices(idx), assign values to dst  according to\n\ndst[:, ... , k] .= src[:, ... , idx[k]...]\n\nNotice that if idx is a vector containing integers and src is a matrix, previous expression simplifies to\n\ndst[:, k] .= src[:, idx[k]]\n\nand k will run over 1:length(idx). \n\nThe elements of idx can be integers or integer tuples and may be repeated.  A single src column can end up being copied into zero, one,  or multiple dst columns.\n\nSee gather! for an in-place version.\n\n\n\n\n\n","category":"function"},{"location":"api/nnlib/#NNlib.scatter!","page":"NNlib","title":"NNlib.scatter!","text":"scatter!(op, dst, src, idx)\n\nScatter operation, which scatters data in src and assigns to dst according to idx. A binary reduction operator op is applied during the scatter.  For each index k in idx, accumulates values in dst according to\n\ndst[:, ..., idx[k]...] = (op).(dst[:, ..., idx[k]...], src[:, ..., k...])\n\nArguments\n\nop: Operations to be applied on dst and src, e.g. +, -, *, /, max, min and mean.\ndst: The destination for src to aggregate to. This argument will be mutated.\nsrc: The source data for aggregating.\nidx: The mapping for aggregation from source (index) to destination (value).         The idx array can contain either integers or tuples.\n\n\n\n\n\n","category":"function"},{"location":"api/nnlib/#NNlib.scatter","page":"NNlib","title":"NNlib.scatter","text":"scatter(op, src, idx; [init, dstsize])\n\nScatter operation allocating a destination array dst and  calling scatter!(op, dst, src, idx) on it.\n\nIf init is provided, it is used to initialize the content of dst. Otherwise, the init values is inferred from the reduction operator op for some common operators (e.g. init = 0 for op = +). \n\nIf dstsize is provided, it will be used to define the size of destination array, otherwise it will be inferred by src and idx.\n\nSee scatter! for the details.\n\n\n\n\n\n","category":"function"},{"location":"#GraphNeuralNetworks","page":"Home","title":"GraphNeuralNetworks","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is the documentation page for the GraphNeuralNetworks.jl library.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A graph neural network library for Julia based on the deep learning framework Flux.jl. Its most relevant features are:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Provides CUDA support.\nIt's integrated with the JuliaGraphs ecosystem.\nImplements many common graph convolutional layers.\nPerforms fast operations on batched graphs. \nMakes it easy to define custom graph convolutional layers.","category":"page"},{"location":"#Package-overview","page":"Home","title":"Package overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Let's give a brief overview of the package solving a   graph regression problem on fake data. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Usage examples on real datasets can be found in the examples folder. ","category":"page"},{"location":"#Data-preparation","page":"Home","title":"Data preparation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"First, we create our dataset consisting in multiple random graphs and associated data features.  that we batch together into a unique graph.","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using GraphNeuralNetworks, LightGraphs, Flux, CUDA, Statistics\n\njulia> all_graphs = GNNGraph[];\n\njulia> for _ in 1:1000\n           g = GNNGraph(random_regular_graph(10, 4),  \n                       ndata=(; x = randn(Float32, 16,10)),  # input node features\n                       gdata=(; y = randn(Float32)))         # regression target   \n           push!(all_graphs, g)\n       end\n\njulia> gbatch = Flux.batch(all_graphs)\nGNNGraph:\n    num_nodes = 10000\n    num_edges = 40000\n    num_graphs = 1000\n    ndata:\n        x => (16, 10000)\n    edata:\n    gdata:\n        y => (1000,)","category":"page"},{"location":"#Model-building","page":"Home","title":"Model building","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We concisely define our model using as a GNNChain containing 2 graph convolutaional  layers. If CUDA is available, our model will live on the gpu.","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> device = CUDA.functional() ? Flux.gpu : Flux.cpu;\n\njulia> model = GNNChain(GCNConv(16 => 64),\n                        BatchNorm(64),\n                        x -> relu.(x),\n                        GCNConv(64 => 64, relu),\n                        GlobalPool(mean),\n                        Dense(64, 1)) |> device;\n\njulia> ps = Flux.params(model);\n\njulia> opt = ADAM(1f-4);","category":"page"},{"location":"#Training","page":"Home","title":"Training","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Finally, we use a standard Flux training pipeling to fit our dataset. Flux's DataLoader iterates over mini-batches of graphs  (batched together into a GNNGraph object). ","category":"page"},{"location":"","page":"Home","title":"Home","text":"gtrain, _ = getgraph(gbatch, 1:800)\ngtest, _ = getgraph(gbatch, 801:gbatch.num_graphs)\ntrain_loader = Flux.Data.DataLoader(gtrain, batchsize=32, shuffle=true)\ntest_loader = Flux.Data.DataLoader(gtest, batchsize=32, shuffle=false)\n\nloss(g::GNNGraph) = mean((vec(model(g, g.ndata.x)) - g.gdata.y).^2)\n\nloss(loader) = mean(loss(g |> device) for g in loader)\n\nfor epoch in 1:100\n    for g in train_loader\n        g = g |> gpu\n        grad = gradient(() -> loss(g), ps)\n        Flux.Optimise.update!(opt, ps, grad)\n    end\n\n    @info (; epoch, train_loss=loss(train_loader), test_loss=loss(test_loader))\nend","category":"page"}]
}
