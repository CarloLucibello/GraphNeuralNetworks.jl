<!DOCTYPE html><HTML lang="en"><head><script charset="utf-8" src="../../../../../assets/default/multidoc_injector.js" type="text/javascript"></script><script charset="utf-8" type="text/javascript">window.MULTIDOCUMENTER_ROOT_PATH = '/GraphNeuralNetworks.jl/'</script><script charset="utf-8" src="../../../../../assets/default/flexsearch.bundle.js" type="text/javascript"></script><script charset="utf-8" src="../../../../../assets/default/flexsearch_integration.js" type="text/javascript"></script><meta charset="UTF-8"/><meta content="width=device-width, initial-scale=1.0" name="viewport"/><title>GNNGraph · GraphNeuralNetworks.jl</title><script data-outdated-warner="" src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script data-main="../../assets/documenter.js" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" data-theme-name="documenter-dark" data-theme-primary-dark="" href="../../assets/themes/documenter-dark.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="documenter-light" data-theme-primary="" href="../../assets/themes/documenter-light.css" rel="stylesheet" type="text/css"/><script src="../../assets/themeswap.js"></script><link href="../../../../../assets/default/multidoc.css" rel="stylesheet" type="text/css"/><link href="../../../../../assets/default/flexsearch.css" rel="stylesheet" type="text/css"/></head><body><nav id="multi-page-nav"><a class="brand" href="../../../../.."><img alt="home" src="../../../../../logo.svg"/></a><div class="hidden-on-mobile" id="nav-items"><a class="nav-link active nav-item" href="../../../">GraphNeuralNetworks.jl</a><a class="nav-link nav-item" href="../../../../GNNLux.jl/">GNNLux.jl</a><a class="nav-link nav-item" href="../../../../GNNGraphs.jl/">GNNGraphs.jl</a><a class="nav-link nav-item" href="../../../../GNNlib.jl/">GNNlib.jl</a><div class="search nav-item"><input id="search-input" placeholder="Search..."/><ul class="suggestions hidden" id="search-result-container"></ul><div class="search-keybinding">/</div></div></div><button id="multidoc-toggler"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg></button></nav><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">GraphNeuralNetworks.jl</a></span></div><form action="../../search/" class="docs-search"><input class="docs-search-query" id="documenter-search-query" name="q" placeholder="Search docs" type="text"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../gnngraph/">Graphs</a></li><li><a class="tocitem" href="../../messagepassing/">Message Passing</a></li><li><a class="tocitem" href="../../models/">Model Building</a></li><li><span class="tocitem">API Reference</span><ul><li class="is-active"><a class="tocitem" href="">GNNGraph</a><ul class="internal"><li><a class="tocitem" href="#Index"><span>Index</span></a></li><li><a class="tocitem" href="#Docs"><span>Docs</span></a></li></ul></li><li><a class="tocitem" href="../basic/">Basic Layers</a></li><li><a class="tocitem" href="../conv/">Convolutional Layers</a></li><li><a class="tocitem" href="../pool/">Pooling Layers</a></li><li><a class="tocitem" href="../messagepassing/">Message Passing</a></li><li><a class="tocitem" href="../utils/">Utils</a></li></ul></li><li><a class="tocitem" href="../../dev/">Developer Notes</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API Reference</a></li><li class="is-active"><a href="">GNNGraph</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="">GNNGraph</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/master/docs/src/api/gnngraph.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" href="#" id="documenter-settings-button" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" href="#" id="documenter-sidebar-button"></a></div></header><article class="content" id="documenter-page"><h1 id="GNNGraph"><a class="docs-heading-anchor" href="#GNNGraph">GNNGraph</a><a id="GNNGraph-1"></a><a class="docs-heading-anchor-permalink" href="#GNNGraph" title="Permalink"></a></h1><p>Documentation page for the graph type <code>GNNGraph</code> provided GraphNeuralNetworks.jl and its related methods. </p><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#GraphNeuralNetworks.GNNGraph"><code>GraphNeuralNetworks.GNNGraph</code></a></li><li><a href="#Flux.batch"><code>Flux.batch</code></a></li><li><a href="#GraphNeuralNetworks.add_self_loops-Tuple{GNNGraph{var&quot;#s15&quot;} where var&quot;#s15&quot;&lt;:(Tuple{T, T, V} where {T&lt;:(AbstractVector{T} where T), V})}"><code>GraphNeuralNetworks.add_self_loops</code></a></li><li><a href="#GraphNeuralNetworks.adjacency_list-Tuple{GNNGraph}"><code>GraphNeuralNetworks.adjacency_list</code></a></li><li><a href="#GraphNeuralNetworks.edge_index-Tuple{GNNGraph{var&quot;#s16&quot;} where var&quot;#s16&quot;&lt;:(Tuple{T, T, V} where {T&lt;:(AbstractVector{T} where T), V})}"><code>GraphNeuralNetworks.edge_index</code></a></li><li><a href="#GraphNeuralNetworks.getgraph-Tuple{GNNGraph, Int64}"><code>GraphNeuralNetworks.getgraph</code></a></li><li><a href="#GraphNeuralNetworks.normalized_laplacian"><code>GraphNeuralNetworks.normalized_laplacian</code></a></li><li><a href="#GraphNeuralNetworks.scaled_laplacian"><code>GraphNeuralNetworks.scaled_laplacian</code></a></li><li><a href="#LightGraphs.LinAlg.adjacency_matrix"><code>LightGraphs.LinAlg.adjacency_matrix</code></a></li><li><a href="#SparseArrays.blockdiag"><code>SparseArrays.blockdiag</code></a></li><li><a href="#SparseArrays.blockdiag-Tuple{GNNGraph, Vararg{GNNGraph, N} where N}"><code>SparseArrays.blockdiag</code></a></li></ul><h2 id="Docs"><a class="docs-heading-anchor" href="#Docs">Docs</a><a id="Docs-1"></a><a class="docs-heading-anchor-permalink" href="#Docs" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" href="#GraphNeuralNetworks.GNNGraph" id="GraphNeuralNetworks.GNNGraph"><code>GraphNeuralNetworks.GNNGraph</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GNNGraph(data; [graph_type, ndata, edata, gdata, num_nodes, graph_indicator, dir])
GNNGraph(g::GNNGraph; [ndata, edata, gdata])</code></pre><p>A type representing a graph structure and storing also  feature arrays associated to nodes, edges, and to the whole graph (global features). </p><p>A <code>GNNGraph</code> can be constructed out of different objects <code>data</code> expressing the connections inside the graph. The internal representation type is determined by <code>graph_type</code>.</p><p>When constructed from another <code>GNNGraph</code>, the internal graph representation is preserved and shared. The node/edge/global features are transmitted as well, unless explicitely changed though keyword arguments.</p><p>A <code>GNNGraph</code> can also represent multiple graphs batched togheter  (see <a href="#Flux.batch"><code>Flux.batch</code></a> or <a href="#SparseArrays.blockdiag"><code>SparseArrays.blockdiag</code></a>). The field <code>g.graph_indicator</code> contains the graph membership of each node.</p><p>A <code>GNNGraph</code> is a LightGraphs' <code>AbstractGraph</code>, therefore any functionality from the LightGraphs' graph library can be used on it.</p><p><strong>Arguments</strong></p><ul><li><code>data</code>: Some data representing the graph topology. Possible type are <ul><li>An adjacency matrix</li><li>An adjacency list.</li><li>A tuple containing the source and target vectors (COO representation)</li><li>A LightGraphs' graph.</li></ul></li><li><code>graph_type</code>: A keyword argument that specifies                the underlying representation used by the GNNGraph.                Currently supported values are <ul><li><code>:coo</code>. Graph represented as a tuple <code>(source, target)</code>, such that the <code>k</code>-th edge          connects the node <code>source[k]</code> to node <code>target[k]</code>.         Optionally, also edge weights can be given: <code>(source, target, weights)</code>.</li><li><code>:sparse</code>. A sparse adjacency matrix representation.</li><li><code>:dense</code>. A dense adjacency matrix representation.  </li></ul>Default <code>:coo</code>.</li><li><code>dir</code>: The assumed edge direction when given adjacency matrix or adjacency list input data <code>g</code>.        Possible values are <code>:out</code> and <code>:in</code>. Default <code>:out</code>.</li><li><code>num_nodes</code>: The number of nodes. If not specified, inferred from <code>g</code>. Default <code>nothing</code>.</li><li><code>graph_indicator</code>: For batched graphs, a vector containing the graph assigment of each node. Default <code>nothing</code>.  </li><li><code>ndata</code>: Node features. A named tuple of arrays whose last dimension has size num_nodes.</li><li><code>edata</code>: Edge features. A named tuple of arrays whose whose last dimension has size num_edges.</li><li><code>gdata</code>: Global features. A named tuple of arrays whose has size num_graphs. </li></ul><p><strong>Usage.</strong></p><pre><code class="language-julia hljs">using Flux, GraphNeuralNetworks

# Construct from adjacency list representation
data = [[2,3], [1,4,5], [1], [2,5], [2,4]]
g = GNNGraph(data)

# Number of nodes, edges, and batched graphs
g.num_nodes  # 5
g.num_edges  # 10 
g.num_graphs # 1 

# Same graph in COO representation
s = [1,1,2,2,2,3,4,4,5,5]
t = [2,3,1,4,5,3,2,5,2,4]
g = GNNGraph(s, t)

# From a LightGraphs' graph
g = GNNGraph(erdos_renyi(100, 20))

# Add 2 node feature arrays
g = GNNGraph(g, ndata = (x=rand(100, g.num_nodes), y=rand(g.num_nodes)))

# Add node features and edge features with default names `x` and `e` 
g = GNNGraph(g, ndata = rand(100, g.num_nodes), edata = rand(16, g.num_edges))

g.ndata.x
g.ndata.e

# Send to gpu
g = g |&gt; gpu

# Collect edges' source and target nodes.
# Both source and target are vectors of length num_edges
source, target = edge_index(g)</code></pre></div><a class="docs-sourcelink" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/210d2c861cca06a9471fe649f1e38812cfb027e3/src/gnngraph.jl#L14-L100" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#GraphNeuralNetworks.add_self_loops-Tuple{GNNGraph{var&quot;#s15&quot;} where var&quot;#s15&quot;&lt;:(Tuple{T, T, V} where {T&lt;:(AbstractVector{T} where T), V})}" id="GraphNeuralNetworks.add_self_loops-Tuple{GNNGraph{var&quot;#s15&quot;} where var&quot;#s15&quot;&lt;:(Tuple{T, T, V} where {T&lt;:(AbstractVector{T} where T), V})}"><code>GraphNeuralNetworks.add_self_loops</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">add_self_loops(g::GNNGraph)</code></pre><p>Return a graph with the same features as <code>g</code> but also adding edges connecting the nodes to themselves.</p><p>Nodes with already existing self-loops will obtain a second self-loop.</p></div><a class="docs-sourcelink" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/210d2c861cca06a9471fe649f1e38812cfb027e3/src/gnngraph.jl#L387-L395" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#GraphNeuralNetworks.adjacency_list-Tuple{GNNGraph}" id="GraphNeuralNetworks.adjacency_list-Tuple{GNNGraph}"><code>GraphNeuralNetworks.adjacency_list</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">adjacency_list(g; dir=:out)</code></pre><p>Return the adjacency list representation (a vector of vectors) of the graph <code>g</code>.</p><p>Calling <code>a</code> the adjacency list, if <code>dir=:out</code><code>a[i]</code> will contain the neighbors of node <code>i</code> through outgoing edges. If <code>dir=:in</code>, it will contain neighbors from incoming edges instead.</p></div><a class="docs-sourcelink" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/210d2c861cca06a9471fe649f1e38812cfb027e3/src/gnngraph.jl#L264-L274" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#GraphNeuralNetworks.edge_index-Tuple{GNNGraph{var&quot;#s16&quot;} where var&quot;#s16&quot;&lt;:(Tuple{T, T, V} where {T&lt;:(AbstractVector{T} where T), V})}" id="GraphNeuralNetworks.edge_index-Tuple{GNNGraph{var&quot;#s16&quot;} where var&quot;#s16&quot;&lt;:(Tuple{T, T, V} where {T&lt;:(AbstractVector{T} where T), V})}"><code>GraphNeuralNetworks.edge_index</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">edge_index(g::GNNGraph)</code></pre><p>Return a tuple containing two vectors, respectively storing  the source and target nodes for each edges in <code>g</code>.</p><pre><code class="language-julia hljs">s, t = edge_index(g)</code></pre></div><a class="docs-sourcelink" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/210d2c861cca06a9471fe649f1e38812cfb027e3/src/gnngraph.jl#L207-L216" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#GraphNeuralNetworks.getgraph-Tuple{GNNGraph, Int64}" id="GraphNeuralNetworks.getgraph-Tuple{GNNGraph, Int64}"><code>GraphNeuralNetworks.getgraph</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">getgraph(g::GNNGraph, i; nmap=false)</code></pre><p>Return the subgraph of <code>g</code> induced by those nodes <code>j</code> for which <code>g.graph_indicator[j] == i</code> or, if <code>i</code> is a collection, <code>g.graph_indicator[j] ∈ i</code>.  In other words, it extract the component graphs from a batched graph. </p><p>If <code>nmap=true</code>, return also a vector <code>v</code> mapping the new nodes to the old ones.  The node <code>i</code> in the subgraph will correspond to the node <code>v[i]</code> in <code>g</code>.</p></div><a class="docs-sourcelink" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/210d2c861cca06a9471fe649f1e38812cfb027e3/src/gnngraph.jl#L513-L523" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#GraphNeuralNetworks.normalized_laplacian" id="GraphNeuralNetworks.normalized_laplacian"><code>GraphNeuralNetworks.normalized_laplacian</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">normalized_laplacian(g, T=Float32; add_self_loops=false, dir=:out)</code></pre><p>Normalized Laplacian matrix of graph <code>g</code>.</p><p><strong>Arguments</strong></p><ul><li><code>g</code>: A <code>GNNGraph</code>.</li><li><code>T</code>: result element type.</li><li><code>add_self_loops</code>: add self-loops while calculating the matrix.</li><li><code>dir</code>: the edge directionality considered (:out, :in, :both).</li></ul></div><a class="docs-sourcelink" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/210d2c861cca06a9471fe649f1e38812cfb027e3/src/gnngraph.jl#L326-L337" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#GraphNeuralNetworks.scaled_laplacian" id="GraphNeuralNetworks.scaled_laplacian"><code>GraphNeuralNetworks.scaled_laplacian</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">scaled_laplacian(g, T=Float32; dir=:out)</code></pre><p>Scaled Laplacian matrix of graph <code>g</code>, defined as <span>$\hat{L} = \frac{2}{\lambda_{max}} L - I$</span> where <span>$L$</span> is the normalized Laplacian matrix.</p><p><strong>Arguments</strong></p><ul><li><code>g</code>: A <code>GNNGraph</code>.</li><li><code>T</code>: result element type.</li><li><code>dir</code>: the edge directionality considered (:out, :in, :both).</li></ul></div><a class="docs-sourcelink" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/210d2c861cca06a9471fe649f1e38812cfb027e3/src/gnngraph.jl#L355-L366" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#SparseArrays.blockdiag-Tuple{GNNGraph, Vararg{GNNGraph, N} where N}" id="SparseArrays.blockdiag-Tuple{GNNGraph, Vararg{GNNGraph, N} where N}"><code>SparseArrays.blockdiag</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">blockdiag(xs::GNNGraph...)</code></pre><p>Equivalent to <a href="#Flux.batch"><code>Flux.batch</code></a>.</p></div><a class="docs-sourcelink" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/210d2c861cca06a9471fe649f1e38812cfb027e3/src/gnngraph.jl#L479-L483" target="_blank">source</a></section></article><article class="docstring"><header><a class="docstring-binding" href="#Flux.batch" id="Flux.batch"><code>Flux.batch</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">batch(xs::Vector{&lt;:GNNGraph})</code></pre><p>Batch together multiple <code>GNNGraph</code>s into a single one  containing the total number of original nodes and edges.</p><p>Equivalent to <a href="#SparseArrays.blockdiag"><code>SparseArrays.blockdiag</code></a>.</p></div><a class="docs-sourcelink" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/210d2c861cca06a9471fe649f1e38812cfb027e3/src/gnngraph.jl#L492-L499" target="_blank">source</a></section><section><div><pre><code class="nohighlight hljs">batch(xs)</code></pre><p>Batch the arrays in <code>xs</code> into a single array.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; Flux.batch([[1,2,3],[4,5,6]])
3×2 Matrix{Int64}:
 1  4
 2  5
 3  6</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" href="#SparseArrays.blockdiag" id="SparseArrays.blockdiag"><code>SparseArrays.blockdiag</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">blockdiag(xs::GNNGraph...)</code></pre><p>Equivalent to <a href="#Flux.batch"><code>Flux.batch</code></a>.</p></div><a class="docs-sourcelink" href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/blob/210d2c861cca06a9471fe649f1e38812cfb027e3/src/gnngraph.jl#L479-L483" target="_blank">source</a></section><section><div><pre><code class="nohighlight hljs">blockdiag(A...)</code></pre><p>Concatenate matrices block-diagonally. Currently only implemented for sparse matrices.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; blockdiag(sparse(2I, 3, 3), sparse(4I, 2, 2))
5×5 SparseMatrixCSC{Int64, Int64} with 5 stored entries:
 2  ⋅  ⋅  ⋅  ⋅
 ⋅  2  ⋅  ⋅  ⋅
 ⋅  ⋅  2  ⋅  ⋅
 ⋅  ⋅  ⋅  4  ⋅
 ⋅  ⋅  ⋅  ⋅  4</code></pre></div></section><section><div><pre><code class="nohighlight hljs">blockdiag(g, h)</code></pre><p>Return a graph with <span>$|V(g)| + |V(h)|$</span> vertices and <span>$|E(g)| + |E(h)|$</span> edges where the vertices and edges from graph <code>h</code> are appended to graph <code>g</code>.</p><p><strong>Implementation Notes</strong></p><p>Preserves the eltype of the input graph. Will error if the number of vertices in the generated graph exceeds the <code>eltype</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; g1 = SimpleDiGraph([0 1 0 0 0; 0 0 1 0 0; 1 0 0 1 0; 0 0 0 0 1; 0 0 0 1 0]);

julia&gt; g2 = SimpleDiGraph([0 1 0; 0 0 1; 1 0 0]);

julia&gt; blockdiag(g1, g2)
{8, 9} directed simple Int64 graph

julia&gt; foreach(println, edges(blockdiag(g1, g2)))
Edge 1 =&gt; 2
Edge 2 =&gt; 3
Edge 3 =&gt; 1
Edge 3 =&gt; 4
Edge 4 =&gt; 5
Edge 5 =&gt; 4
Edge 6 =&gt; 7
Edge 7 =&gt; 8
Edge 8 =&gt; 6</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" href="#LightGraphs.LinAlg.adjacency_matrix" id="LightGraphs.LinAlg.adjacency_matrix"><code>LightGraphs.LinAlg.adjacency_matrix</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">adjacency_matrix(g[, T=Int; dir=:out])</code></pre><p>Return a sparse adjacency matrix for a graph, indexed by <code>[u, v]</code> vertices. Non-zero values indicate an edge from <code>u</code> to <code>v</code>. Users may override the default data type (<code>Int</code>) and specify an optional direction.</p><p><strong>Optional Arguments</strong></p><p><code>dir=:out</code>: <code>:in</code>, <code>:out</code>, or <code>:both</code> are currently supported.</p><p><strong>Implementation Notes</strong></p><p>This function is optimized for speed and directly manipulates CSC sparse matrix fields.</p></div></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../models/">« Model Building</a><a class="docs-footer-nextpage" href="../basic/">Basic Layers »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label></p><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div><p></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.7 on <span class="colophon-date" title="Tuesday 5 October 2021 05:19">Tuesday 5 October 2021</span>. Using Julia version 1.6.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></HTML>